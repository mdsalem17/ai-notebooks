In `summarizer.ipynb` notebook, we are interested in building an Abstractive Text Summarization model. In order to do so, we implemented a Transformer-based model trained from scratch on CNN/DailyMail non-anonymized summarization dataset. 

Library used: [Trax â€” Deep Learning with Clear Code and Speed](https://github.com/google/trax) library, maintained by Google Brain team.